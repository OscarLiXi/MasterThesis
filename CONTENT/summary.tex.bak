%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Summary, Discussion and Future Works}
\label{chap:summary}

%In conclusion, we suggest a robust sensory fusing framework to be applied on visual-inertial odometry. This framework is lead by integrating IMU measurement from local frame to global frame, with additional extrasensory data (vision data) to complement unobservable parameters of IMU. We further explore a self-adapt map scale method and keyframe-based local bundle adjustment to increase the estimation accuracy.

%The advantages of this framework is that system does not keep visual landmarks and IMU measurement, therefore runs in a constant time complexity, which can be easily extended a large scaled scene. The drawback is that it is more reliable to the performance of visual odometry, meaning that if the correction data gives bad feedback, the whole system is easily collapsed. However we have provided experimental results that our framework can give more stable and accuracy estimation of camera pose than current state-of-art visual odometry on same data sequence, thus we argue that our work is meaningful and the results of our system will further be increased with the development of visual odometry.

%Another way to resolve this drawback is to apply feature-based visual-inertial methods (tightly-coupled IMU integration), which could be a potential future work. More recent literatures show that feature-based VIO performs well and can be used commercially. \cite{forster2015imu} uses pre-integration theory and manifold optimization to optimize IMU and visual information together; \cite{hesch2014consistency}, which is considered the foundation algorithm of Google Project Tango, runs a consistency analysis and modify some terms of traditional IMU integration to obtain less variation results. Unfortunately, we could not compare those latest algorithm due the un-release of their codes, it is definitely worth to try their ideas of VIO in the future. Though in such tighly-coupled visual-inertial SLAM, computational complexity is severely increased, therefore more simplifications of optimization step has to be explored, like pre-integration theory applied in \cite{forster2015imu}. 

%Due to the lack of resources and time, we are not available to build a real IMU-camera platform in this master thesis. A more rigorous denoise technique and more complicated noise model might have to be applied when using real data, which is also a possible way to work with in the future. 

In this master thesis, we have suggested a robust sensory fusing framework, which can be applied on real-time mobile robot navigation. Visual data (\eg, camera) can provide rich information, however it is rather time-consuming to analysis it; while inertial sensor (IMU) provides accurate estimation of its observable variables but needs compensation in its unobservable parameters. We aim to improve the localization quality by fusing such multiple sensory data. This framework is lead by integrating IMU measurement from local frame to global frame, with additional extrasensory data (vision data) to complement unobservable parameters of IMU. We further explore a self-adapt map scale method and keyframe-based local bundle adjustment to increase the estimation accuracy.

In experimental parts, we demonstrate several experiments to provide evidences that our framework is robust and correct step by step. First we examine our IMU integration method in regular and special trajectory, second we show that our framework is more robust and accurate than single visual odometry, at last we show that a keyframe-based local bundle adjustment to further increase the estimation accuracy, and whole system runs in real-time.

The advantages of this framework is that system does not keep visual landmarks and IMU measurement, therefore runs in a constant time complexity, which can be easily extended a large scaled scene. The drawback is that such a framework can be regarded a single iteration of optimization step, hence the solution is sub-optimal. As we have discussed in the first few parts, the trade-off of computational complexity and estimation accuracy is inevitable, once we have used complete optimization solution, system will keep certain numbers of former states hence might be more time-consuming.

Therefore we briefly introduce our current interests in Chapter \ref{chap:current}. We are supposed to show that our current work can be transformed into a non-linear optimization solution easily. The cost function is formed by visual error (reprojection error) and IMU temporal error. By establishing such a cost function, one can easily solve it by performing a manifold optimization methods as we have introduced in Section \ref{sec:exponential}. One thing left is to decrease the computational time in optimization, such as landmark position elimination (structureless approach) in tightly-coupled VIO \cite{mourikis2007multi, forster2015imu}, or pre-integration theory \cite{forster2015imu} to avoid repeatedly computing IMU integration. Another potential improvement is by the work in \cite{hesch2014consistency}, which provides a consistency analysis and modify some terms of traditional IMU integration to obtain estimation results with less variation .

One pity of this master thesis is that we are not able to build a real IMU-camera platform in this master thesis due to the lack of resources and time. A more rigorous denoise technique and more complicated noise model might have to be applied when using real data, which is also a possible working area in the future.

