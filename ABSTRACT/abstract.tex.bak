%% The text of your abstract and nothing else (other than comments) goes here.
%% It will be single-spaced and the rest of the text that is supposed to go on
%% the abstract page will be generated by the abstractpage environment.  This
%% file should be \input (not \include 'd) from cover.tex.

Mobile robot navigation has been an attractive topic in the Robotics area for a long time. Mobile robots, equipped with different types of sensors, consistently estimate their own location while moving around the unknown environment. \textit{Visual SLAM} simultaneously locates robots' pose and mapping via analysing information obtained from visual sensor. However due the costly computational complexity of camera, it is hard to gain a high-quality pose estimation while the whole system runs in real-time. \textit{Inertial Measurement Unit} (IMU) measures rotational rate and acceleration in the higher frequency, which has been proven an appropriate compensation to single camera in such a navigation system. In this master thesis, we aim to exploit a visual-inertial odometry, to further improve localization results by fusing visual data and IMU data, especially we apply a loosely-coupled visual-inertial integration method to keep our system runs in a constant time. 

We first discuss the types of Visual SLAM. Visual SLAM has two traditional approaches, which are filter-based methods and keyframe-based methods respectively. Filter-based methods normally marginalise all the former information to obtain the current pose estimation, whereas keyframe-based methods keep some former poses and applies bundle adjustment to optimize the results. We finally choose keyframe-based visual SLAM to be correction data in our Kalman filter framework because it is more effici. We then discuss the way to integrate IMU data. We first learn \textit{quaternion} and its operation. Instead of using Euler angle (Gimbal Lock) or rotational matrix (high memory cost), we form the system rotation by quaternion. Followed by that, we also discuss the time-integration and time-derivative related to quaternion, and suggest a error-state Kalman filter to propagate system state while tracking the system uncertainty. To fuse the visual data and IMU data, we suggest a adapted map scale method to automatically propagate map scale parameter, therefore solve the unknown map scale problem in mono visual SLAM. We also suggest a keyframe-based bundle adjustment to further improve the tracking quality. Our experiments show that our suggested framework obtain more accurate and stable results than single visual odometry, and our system can be easily extended to large scaled scene.

In addition to discussing Kalman filter based framework, we show that our work can be transferred to a manifold optimization problem by forming such a cost function. We introduce the general way of manifold optimization, and several ideas to reduce the computational time at last.

